{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LLM SSH Test\n",
    "\n",
    "Author: Heikki \"zokol\" Juva\n",
    "\n",
    "Email: heikki@juva.lu\n",
    "\n",
    "Date: 05.04.2025\n",
    "\n",
    "## Intro\n",
    "\n",
    "Since running into LMStudio, I started wondering if it could be utilized for complex and cyclic self-evolving tasks.\n",
    "I imagined something where LLM generates the commands to run, analyzes the results and then takes decisions to either run another command or give a final answer.\n",
    "\n",
    "This notebook is one of those tests around this idea, in this case, giving LLM ability to run any commands in a remote system via SSH.\n",
    "\n",
    "Code is mostly based on the examples in LM Studio documentation (https://lmstudio.ai/docs/app/api/tools), with some modifications of my own.\n",
    "\n",
    "## Setup\n",
    "\n",
    "* Kali 2024.3 running on a VMware Workstation (flag.txt 'hidden' under /home/kali/secret)\n",
    "* LM Studio running on a local desktop (1080 ti GPU, nothing fancy), with API server enabled and running on port 1234\n",
    "* Pycharm as IDE for Jupyter\n",
    "\n",
    "## Some terminology\n",
    "\n",
    "* `execute_ssh_command`: function to run any command in the remote system via SSH\n",
    "* `run_task`: function to run a task, which is a command to be executed in the remote system\n",
    "* `task`: task to be executed in the remote system\n",
    "* `tools`: list of tools to be used in the task\n",
    "* `messages`: list of messages to be used in the task\n",
    "* `client`: LM Studio client config\n",
    "* `model`: LM Studio model (so far best results with `qwen2.5-7b-instruct-1m`)\n",
    "\n",
    "## Code"
   ],
   "id": "9db76933c2de3800"
  },
  {
   "cell_type": "code",
   "id": "5facbbe56c3307f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:38:30.665667Z",
     "start_time": "2025-04-05T19:38:30.145846Z"
    }
   },
   "source": [
    "import json\n",
    "import paramiko\n",
    "from openai import OpenAI\n",
    "\n",
    "# Config\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "model = \"lmstudio-community/qwen2.5-7b-instruct-1m\"\n",
    "RECURSION_LIMIT = 5\n",
    "DEBUG = True\n",
    "TOKEN_LIMIT = 4000\n",
    "\n",
    "# Target system config\n",
    "IP = '192.168.40.132'\n",
    "USERNAME = \"kali\"\n",
    "PASSWORD = \"kali\"\n",
    "\n",
    "class FinalAnalysisDone(Exception):\n",
    "    \"\"\"\n",
    "    Custom exception to indicate that the final analysis is done.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def execute_ssh_command(command: str):\n",
    "\n",
    "    # Create a new SSH client\n",
    "    client = paramiko.SSHClient()\n",
    "    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "    # Connect to the remote host\n",
    "    client.connect(IP, username=USERNAME, password=PASSWORD)\n",
    "\n",
    "    # Run a command\n",
    "    stdin, stdout, stderr = client.exec_command(command)\n",
    "\n",
    "    # Parse results\n",
    "    res = \"\"\n",
    "\n",
    "    # If command returns error, add it to the result\n",
    "    # If standard error is not returned, calling read() will throw an OSError\n",
    "    try:\n",
    "        res += stderr.read().decode()\n",
    "    except OSError as e:\n",
    "        pass\n",
    "\n",
    "    # If command returns standard output, add it to the result\n",
    "    # If standard output is not returned, calling read() will throw an OSError\n",
    "    try:\n",
    "        res += stdout.read().decode()\n",
    "    except OSError as e:\n",
    "        pass\n",
    "\n",
    "    if len(res) == 0:\n",
    "        res = \"ERROR: No output from command \" + command\n",
    "\n",
    "    # To avoid hitting the token limit, we need to limit the output size\n",
    "    output_limit = int(TOKEN_LIMIT / RECURSION_LIMIT*2)\n",
    "    if len(res) > output_limit:\n",
    "        res = res[:output_limit] + \"\\n\\n...output truncated...\"\n",
    "\n",
    "    # Print the output of the command\n",
    "    if DEBUG: print(f\"DEBUG ----- START OF SSH OUTPUT -----\\n\\n {USERNAME}@{IP}$ {command}\\n{res} \\n\\n----- END OF SSH OUTPUT -----\", flush=True)\n",
    "\n",
    "    # Close the connection\n",
    "    client.close()\n",
    "\n",
    "    # Return the result to LLM\n",
    "    return f\"{USERNAME}@{IP}$ {command}\\n{res}\"\n",
    "\n",
    "def run_task(task, history=\"\", exec=None, recursion_depth=0):\n",
    "    \"\"\"\n",
    "    This function runs one round of LLM processing, taking a task as an input and firing anohter recursive round if needed.\n",
    "    :param task (str): User's task or prompt for the LLM\n",
    "    :param history (str): History of previous LLM calls and tool executions\n",
    "    :param exec (str): Command to be executed in the target system shell\n",
    "    :param recursion_depth (int): Recursion depth, used to limit the number of recursive calls\n",
    "    :return (str): Output of the LLM based on the task and the results of the tool calls\n",
    "    \"\"\"\n",
    "\n",
    "    history += f\"--------- START OF ROUND {recursion_depth} ---------------\\n\"\n",
    "\n",
    "    # Initialize command result from previous round\n",
    "    # If this is the first round, this will stay empty\n",
    "    pre_result = \"\"\n",
    "\n",
    "    # Check if we know a command to be executed from previous round\n",
    "    if exec:\n",
    "        # If on previous round LLM recommended an command to be executed, run it and return the result before next LLM call\n",
    "        pre_result = execute_ssh_command(exec)\n",
    "        if DEBUG: print(f\"Result of pre-command execution: {pre_result}\", flush=True)\n",
    "        history += f\"{pre_result}\\n\\n\"\n",
    "\n",
    "    # Define messages for the LLM prompt\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a skilled cybersecurity expert and ethical hacker. Use the supplied tools to complete the given task. Task always starts with TASK:: and ends with ::END Follow common frameworks and workflows, like OWASP TOP10. Base your answer only on given information and the results of the tools you call. Do not make up any information. Base all your actions and statements on scientific or technical grounds. Verify the results of the tools you have called. If the tool returns an error, analyze the error and act accordingly. If you need to run the tool again with another command and parameters, answer with EXEC:: followed by the new command. If you receive a prompt containing HISTORY:: it is followed by your previous answers to this topic, including tools you have executed and results from these tools, ending with ::HISTORY_END. If you receive a prompt containing RES:: followed by text, it is the result of a command you wished to run on previous run. Everything after RES:: is the results of the command executed, ending with ::RES_END. If you are not sure about the answer, try with another command. If you are not sure about the result of the tool call, do not use it. If you are not sure about the answer, say 'I don't know'. If you give recommendations or instructions, make sure they are safe and do not cause any harm. Give technical and scientific references to all recommendations you make. Remember to always try harder, never give up.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"TASK::\" + task + \"::END HISTORY::\" + history + \"::HISTORY_END RES::\" +  pre_result + \"::RES_END\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Define the tools for the LLM to use\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"execute_ssh_command\",\n",
    "                \"description\": \"Execute any command in target system shell. Call this whenever you need to run a command. You need to know a command that the shell (zsh, bash, sh, etc.) allows to be executed to use this function.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"command\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"command to be executed, including all arguments\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"command\"],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Execute the task with LM Studio\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    # Print the model response\n",
    "    if DEBUG:\n",
    "        print(\"\\nModel response requesting tool call:\\n\", flush=True)\n",
    "        print(response, flush=True)\n",
    "\n",
    "    # Prepare the chat completion call payload\n",
    "    completion_messages_payload = [\n",
    "        messages[0],\n",
    "        messages[1]\n",
    "    ]\n",
    "\n",
    "    # Check if the model generated a function call\n",
    "    if hasattr(response, \"choices\"):\n",
    "        if len(response.choices) > 0:\n",
    "            if hasattr(response.choices[0], \"message\"):\n",
    "                # Check if the model generated a function call\n",
    "                if hasattr(response.choices[0].message, \"tool_calls\"):\n",
    "                    if response.choices[0].message.tool_calls is None:\n",
    "                        if DEBUG: print(\"DEBUG: No tool call found in the model response.\", flush=True)\n",
    "                    else:\n",
    "                        tool_call = response.choices[0].message.tool_calls[0]\n",
    "                        arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                        command = arguments.get(\"command\")\n",
    "\n",
    "                        # Call the get_delivery_date function with the extracted order_id\n",
    "                        result = execute_ssh_command(command)\n",
    "                        history += f\"{result}\\n\\n\"\n",
    "\n",
    "                        assistant_tool_call_request_message = {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"tool_calls\": [\n",
    "                                {\n",
    "                                    \"id\": response.choices[0].message.tool_calls[0].id,\n",
    "                                    \"type\": response.choices[0].message.tool_calls[0].type,\n",
    "                                    \"function\": response.choices[0].message.tool_calls[0].function,\n",
    "                                }\n",
    "                            ],\n",
    "                        }\n",
    "\n",
    "                        # Create a message containing the result of the function call\n",
    "                        function_call_result_message = {\n",
    "                            \"role\": \"tool\",\n",
    "                            \"content\": json.dumps(\n",
    "                                {\n",
    "                                    \"command\": command,\n",
    "                                    \"result\": result,\n",
    "                                }\n",
    "                            ),\n",
    "                            \"tool_call_id\": response.choices[0].message.tool_calls[0].id,\n",
    "                        }\n",
    "\n",
    "                        # Add tool results to the completion messages payload\n",
    "                        completion_messages_payload.append(assistant_tool_call_request_message)\n",
    "                        completion_messages_payload.append(function_call_result_message)\n",
    "\n",
    "                        # Call the OpenAI API's chat completions endpoint to send the tool call result back to the model\n",
    "                        # LM Studio\n",
    "                        response = client.chat.completions.create(\n",
    "                            model=model,\n",
    "                            messages=completion_messages_payload,\n",
    "                        )\n",
    "\n",
    "                        if DEBUG: print(\"\\nFinal model response with knowledge of the tool call result:\\n\", flush=True)\n",
    "                        if DEBUG: print(response.choices[0].message.content, flush=True)\n",
    "\n",
    "                        # Construct previous task and result messages\n",
    "                        history += f\"{response.choices[0].message.content}\\n\\n\"\n",
    "\n",
    "                        if \"EXEC::\" in response.choices[0].message.content:\n",
    "                            # Check if the recursion limit has been reached\n",
    "                            if recursion_depth > RECURSION_LIMIT:\n",
    "                                if DEBUG: print(\"Recursion limit reached, stopping execution and asking for final analysis\", flush=True)\n",
    "\n",
    "                            # Extract the command to be executed\n",
    "                            command_to_execute = response.choices[0].message.content.split(\"EXEC::\")[1].strip()\n",
    "                            if DEBUG: print(f\"Command to execute: {command_to_execute}\", flush=True)\n",
    "\n",
    "                            # Execute the command\n",
    "                            run_task(task, history=history, exec=command_to_execute, recursion_depth=recursion_depth + 1)\n",
    "\n",
    "                # Check if model generated response without tool call\n",
    "                else:\n",
    "                    if DEBUG: print(\"DEBUG: No tool call found in the model response.\", flush=True)\n",
    "                    # Check if the model generated a function call\n",
    "                    if hasattr(response.choices[0].message, \"content\"):\n",
    "                        # Print the model response\n",
    "                        if DEBUG: print(\"\\nModel response without tool call:\\n\", flush=True)\n",
    "                        if DEBUG: print(response.choices[0].message.content, flush=True)\n",
    "                        # If the model generated a response without a tool call, use it as the final analysis\n",
    "                        history += f\"{response.choices[0].message.content}\\n\\n\"\n",
    "\n",
    "    history += f\"--------- END OF ROUND {recursion_depth} ---------------\\n\"\n",
    "    # Run final analysis\n",
    "    if DEBUG: print(\"------------ FINAL ANALYSIS ------------\", flush=True)\n",
    "    run_final_analysis(task=task, history=history)\n",
    "\n",
    "def run_final_analysis(task, history):\n",
    "    \"\"\"\n",
    "    This function runs one round of LLM processing, taking a task and prompt history as an input\n",
    "    :param task (str): User's task or prompt for the LLM\n",
    "    :param history (str): History of previous messages and tool calls\n",
    "    :param recursion_depth (int): Recursion depth, used to limit the number of recursive calls\n",
    "    :return (str): Output of the LLM based on the task and the results of the tool calls\n",
    "    \"\"\"\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"--------START OF INPUT--------\", flush=True)\n",
    "        print(f\"{history}\", flush=True)\n",
    "        print(\"--------END OF INPUT--------\", flush=True)\n",
    "\n",
    "    # Define messages for the LLM prompt\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are top-tier academic cybersecurity expert. Your mission is to give an answer to the users task, based on the log of executed commands and LLM-prompts you are given. Make your answer short and to the point. Do not recommend any additional tooling, if the answer is already in the log. Always repeat the answer even if it exists in the log history, do not assume that user has access to the log history. Task always starts with TASK:: and ends with ::END Follow common frameworks and workflows, like OWASP TOP10. Base your answer only on given information and the results of the tools you call. Do not make up any information without scientific or technical basis. Prompt containing HISTORY:: is followed by your previous answers to this topic, including tools you have executed and results from these tools, ending with ::HISTORY_END. If you are not sure about the answer, say 'I don't know'. If you give recommendations or instructions, make sure they are safe and do not cause any harm. Give references to all recommendations you make.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"TASK::\" + task + \"::END HISTORY::\" + history + \"::HISTORY_END\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Execute the task with LM Studio\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    analysis_text = response.choices[0].message.content\n",
    "\n",
    "    # Clean all tags from the response\n",
    "    tags = [\"TASK::\", \"::END\", \"EXEC::\", \"RES::\", \"::RES_END\", \"HISTORY::\", \"::HISTORY_END\"]\n",
    "    for tag in tags:\n",
    "        analysis_text = analysis_text.replace(tag, \"\")\n",
    "    print(analysis_text, flush=True)\n",
    "    raise FinalAnalysisDone\n",
    "\n",
    "def run(task):\n",
    "    try:\n",
    "        run_task(task)\n",
    "    except FinalAnalysisDone:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\", flush=True)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-05T19:38:35.663531Z",
     "start_time": "2025-04-05T19:38:30.672602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = \"List all real users in the system, that have logged into the system at least once\"\n",
    "run(task)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model response requesting tool call:\n",
      "\n",
      "ChatCompletion(id='chatcmpl-bsd26xhefytttxqy8fy3q', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='370861674', function=Function(arguments='{\"command\":\"who -u\"}', name='execute_ssh_command'), type='function')]))], created=1743881912, model='qwen2.5-7b-instruct-1m', object='chat.completion', service_tier=None, system_fingerprint='qwen2.5-7b-instruct-1m', usage=CompletionUsage(completion_tokens=22, prompt_tokens=541, total_tokens=563, completion_tokens_details=None, prompt_tokens_details=None), stats={})\n",
      "DEBUG ----- START OF SSH OUTPUT -----\n",
      "\n",
      " kali@192.168.40.132$ who -u\n",
      "kali     tty7         2025-04-05 10:18 05:20         906 (:0)\n",
      " \n",
      "\n",
      "----- END OF SSH OUTPUT -----\n",
      "\n",
      "Final model response with knowledge of the tool call result:\n",
      "\n",
      "The user 'kali' has logged into the system at least once.\n",
      "------------ FINAL ANALYSIS ------------\n",
      "--------START OF INPUT--------\n",
      "--------- START OF ROUND 0 ---------------\n",
      "kali@192.168.40.132$ who -u\n",
      "kali     tty7         2025-04-05 10:18 05:20         906 (:0)\n",
      "\n",
      "\n",
      "The user 'kali' has logged into the system at least once.\n",
      "\n",
      "--------- END OF ROUND 0 ---------------\n",
      "\n",
      "--------END OF INPUT--------\n",
      "The list of real users in the system who have logged into the system at least once is ['kali'].\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:38:38.527953Z",
     "start_time": "2025-04-05T19:38:35.675436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = \"What kernel version is running in the system?\"\n",
    "run(task)"
   ],
   "id": "f64c602969f6653c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model response requesting tool call:\n",
      "\n",
      "ChatCompletion(id='chatcmpl-i0nwyxkl2fp56lipanz4j', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='892994432', function=Function(arguments='{\"command\":\"uname -r\"}', name='execute_ssh_command'), type='function')]))], created=1743881915, model='qwen2.5-7b-instruct-1m', object='chat.completion', service_tier=None, system_fingerprint='qwen2.5-7b-instruct-1m', usage=CompletionUsage(completion_tokens=22, prompt_tokens=533, total_tokens=555, completion_tokens_details=None, prompt_tokens_details=None), stats={})\n",
      "DEBUG ----- START OF SSH OUTPUT -----\n",
      "\n",
      " kali@192.168.40.132$ uname -r\n",
      "6.8.11-amd64\n",
      " \n",
      "\n",
      "----- END OF SSH OUTPUT -----\n",
      "\n",
      "Final model response with knowledge of the tool call result:\n",
      "\n",
      "The kernel version running in the system is 6.8.11-amd64.\n",
      "------------ FINAL ANALYSIS ------------\n",
      "--------START OF INPUT--------\n",
      "--------- START OF ROUND 0 ---------------\n",
      "kali@192.168.40.132$ uname -r\n",
      "6.8.11-amd64\n",
      "\n",
      "\n",
      "The kernel version running in the system is 6.8.11-amd64.\n",
      "\n",
      "--------- END OF ROUND 0 ---------------\n",
      "\n",
      "--------END OF INPUT--------\n",
      "The kernel version running in the system is 6.8.11-amd64.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:38:56.225955Z",
     "start_time": "2025-04-05T19:38:38.540352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = \"Identify the running services in the system\"\n",
    "run(task)"
   ],
   "id": "dd203c968644161c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model response requesting tool call:\n",
      "\n",
      "ChatCompletion(id='chatcmpl-umwci9q5a3dnibb9terem', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='788395352', function=Function(arguments='{\"command\":\"systemctl list-units --type=service --state=running\"}', name='execute_ssh_command'), type='function')]))], created=1743881918, model='qwen2.5-7b-instruct-1m', object='chat.completion', service_tier=None, system_fingerprint='qwen2.5-7b-instruct-1m', usage=CompletionUsage(completion_tokens=32, prompt_tokens=532, total_tokens=564, completion_tokens_details=None, prompt_tokens_details=None), stats={})\n",
      "DEBUG ----- START OF SSH OUTPUT -----\n",
      "\n",
      " kali@192.168.40.132$ systemctl list-units --type=service --state=running\n",
      "  UNIT                     LOAD   ACTIVE SUB     DESCRIPTION\n",
      "  accounts-daemon.service  loaded active running Accounts Service\n",
      "  colord.service           loaded active running Manage, Install and Generate Color Profiles\n",
      "  cron.service             loaded active running Regular background program processing daemon\n",
      "  dbus.service             loaded active running D-Bus System Message Bus\n",
      "  getty@tty1.service       loaded active running Getty on tty1\n",
      "  haveged.service          loaded active running Entropy Daemon based on the HAVEGE algorithm\n",
      "  lightdm.service          loaded active running Light Display Manager\n",
      "  ModemManager.service     loaded active running Modem Manager\n",
      "  NetworkManager.service   loaded active running Network Manager\n",
      "  open-vm-tools.service    loaded active running Service for virtual machines hosted on VMware\n",
      "  polkit.service           loaded active running Authorization Manager\n",
      "  rsyslog.service          loaded active running System Logging Service\n",
      "  rtkit-daemon.service     loaded active running RealtimeKit Scheduling Policy Service\n",
      "  ssh.service              loaded active running OpenBSD Secure Shell server\n",
      "  systemd-journald.service loaded active running Journal Service\n",
      "  systemd-logind.service   loaded active running User Login Management\n",
      "  systemd-udevd.service    loaded active running Rule-based Manager for Device Events and Files\n",
      "  udisks2.service          loaded active running Disk Manager\n",
      "  upower.service           loaded active running Daemon for power management\n",
      "  user@1000.service        loaded active running User Manager for UID 1000\n",
      "  user@1\n",
      "\n",
      "...output truncated... \n",
      "\n",
      "----- END OF SSH OUTPUT -----\n",
      "\n",
      "Final model response with knowledge of the tool call result:\n",
      "\n",
      "The following services are currently running on the system:\n",
      "\n",
      "1. accounts-daemon.service - Accounts Service\n",
      "2. colord.service - Manage, Install and Generate Color Profiles\n",
      "3. cron.service - Regular background program processing daemon\n",
      "4. dbus.service - D-Bus System Message Bus\n",
      "5. getty@tty1.service - Getty on tty1\n",
      "6. haveged.service - Entropy Daemon based on the HAVEGE algorithm\n",
      "7. lightdm.service - Light Display Manager\n",
      "8. ModemManager.service - Modem Manager\n",
      "9. NetworkManager.service - Network Manager\n",
      "10. open-vm-tools.service - Service for virtual machines hosted on VMware\n",
      "11. polkit.service - Authorization Manager\n",
      "12. rsyslog.service - System Logging Service\n",
      "13. rtkit-daemon.service - RealtimeKit Scheduling Policy Service\n",
      "14. ssh.service - OpenBSD Secure Shell server\n",
      "15. systemd-journald.service - Journal Service\n",
      "16. systemd-logind.service - User Login Management\n",
      "17. systemd-udevd.service - Rule-based Manager for Device Events and Files\n",
      "18. udisks2.service - Disk Manager\n",
      "19. upower.service - Daemon for power management\n",
      "20. user@1000.service - User Manager for UID 1000\n",
      "\n",
      "These services are active and loaded on the system at the moment.\n",
      "------------ FINAL ANALYSIS ------------\n",
      "--------START OF INPUT--------\n",
      "--------- START OF ROUND 0 ---------------\n",
      "kali@192.168.40.132$ systemctl list-units --type=service --state=running\n",
      "  UNIT                     LOAD   ACTIVE SUB     DESCRIPTION\n",
      "  accounts-daemon.service  loaded active running Accounts Service\n",
      "  colord.service           loaded active running Manage, Install and Generate Color Profiles\n",
      "  cron.service             loaded active running Regular background program processing daemon\n",
      "  dbus.service             loaded active running D-Bus System Message Bus\n",
      "  getty@tty1.service       loaded active running Getty on tty1\n",
      "  haveged.service          loaded active running Entropy Daemon based on the HAVEGE algorithm\n",
      "  lightdm.service          loaded active running Light Display Manager\n",
      "  ModemManager.service     loaded active running Modem Manager\n",
      "  NetworkManager.service   loaded active running Network Manager\n",
      "  open-vm-tools.service    loaded active running Service for virtual machines hosted on VMware\n",
      "  polkit.service           loaded active running Authorization Manager\n",
      "  rsyslog.service          loaded active running System Logging Service\n",
      "  rtkit-daemon.service     loaded active running RealtimeKit Scheduling Policy Service\n",
      "  ssh.service              loaded active running OpenBSD Secure Shell server\n",
      "  systemd-journald.service loaded active running Journal Service\n",
      "  systemd-logind.service   loaded active running User Login Management\n",
      "  systemd-udevd.service    loaded active running Rule-based Manager for Device Events and Files\n",
      "  udisks2.service          loaded active running Disk Manager\n",
      "  upower.service           loaded active running Daemon for power management\n",
      "  user@1000.service        loaded active running User Manager for UID 1000\n",
      "  user@1\n",
      "\n",
      "...output truncated...\n",
      "\n",
      "The following services are currently running on the system:\n",
      "\n",
      "1. accounts-daemon.service - Accounts Service\n",
      "2. colord.service - Manage, Install and Generate Color Profiles\n",
      "3. cron.service - Regular background program processing daemon\n",
      "4. dbus.service - D-Bus System Message Bus\n",
      "5. getty@tty1.service - Getty on tty1\n",
      "6. haveged.service - Entropy Daemon based on the HAVEGE algorithm\n",
      "7. lightdm.service - Light Display Manager\n",
      "8. ModemManager.service - Modem Manager\n",
      "9. NetworkManager.service - Network Manager\n",
      "10. open-vm-tools.service - Service for virtual machines hosted on VMware\n",
      "11. polkit.service - Authorization Manager\n",
      "12. rsyslog.service - System Logging Service\n",
      "13. rtkit-daemon.service - RealtimeKit Scheduling Policy Service\n",
      "14. ssh.service - OpenBSD Secure Shell server\n",
      "15. systemd-journald.service - Journal Service\n",
      "16. systemd-logind.service - User Login Management\n",
      "17. systemd-udevd.service - Rule-based Manager for Device Events and Files\n",
      "18. udisks2.service - Disk Manager\n",
      "19. upower.service - Daemon for power management\n",
      "20. user@1000.service - User Manager for UID 1000\n",
      "\n",
      "These services are active and loaded on the system at the moment.\n",
      "\n",
      "--------- END OF ROUND 0 ---------------\n",
      "\n",
      "--------END OF INPUT--------\n",
      "The running services in the system are as listed below:\n",
      "\n",
      "1. accounts-daemon.service - Accounts Service\n",
      "2. colord.service - Manage, Install and Generate Color Profiles\n",
      "3. cron.service - Regular background program processing daemon\n",
      "4. dbus.service - D-Bus System Message Bus\n",
      "5. getty@tty1.service - Getty on tty1\n",
      "6. haveged.service - Entropy Daemon based on the HAVEGE algorithm\n",
      "7. lightdm.service - Light Display Manager\n",
      "8. ModemManager.service - Modem Manager\n",
      "9. NetworkManager.service - Network Manager\n",
      "10. open-vm-tools.service - Service for virtual machines hosted on VMware\n",
      "11. polkit.service - Authorization Manager\n",
      "12. rsyslog.service - System Logging Service\n",
      "13. rtkit-daemon.service - RealtimeKit Scheduling Policy Service\n",
      "14. ssh.service - OpenBSD Secure Shell server\n",
      "15. systemd-journald.service - Journal Service\n",
      "16. systemd-logind.service - User Login Management\n",
      "17. systemd-udevd.service - Rule-based Manager for Device Events and Files\n",
      "18. udisks2.service - Disk Manager\n",
      "19. upower.service - Daemon for power management\n",
      "20. user@1000.service - User Manager for UID 1000\n",
      "\n",
      "These services are currently active on the system as of the last check.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:39:08.914796Z",
     "start_time": "2025-04-05T19:38:56.238355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = \"List all network services running in the system, including protocol and port\"\n",
    "run(task)"
   ],
   "id": "4fef5f5b7ed79936",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model response requesting tool call:\n",
      "\n",
      "ChatCompletion(id='chatcmpl-37hoytaoc6k1xfzje9qpvs', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='715871099', function=Function(arguments='{\"command\":\"netstat -tunlp\"}', name='execute_ssh_command'), type='function')]))], created=1743881936, model='qwen2.5-7b-instruct-1m', object='chat.completion', service_tier=None, system_fingerprint='qwen2.5-7b-instruct-1m', usage=CompletionUsage(completion_tokens=25, prompt_tokens=537, total_tokens=562, completion_tokens_details=None, prompt_tokens_details=None), stats={})\n",
      "DEBUG ----- START OF SSH OUTPUT -----\n",
      "\n",
      " kali@192.168.40.132$ netstat -tunlp\n",
      "(Not all processes could be identified, non-owned process info\n",
      " will not be shown, you would have to be root to see it all.)\n",
      "Active Internet connections (only servers)\n",
      "Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \n",
      "tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -                   \n",
      "tcp        0      0 127.0.0.1:33363         0.0.0.0:*               LISTEN      -                   \n",
      "tcp        0      0 127.0.0.1:42039         0.0.0.0:*               LISTEN      -                   \n",
      "tcp6       0      0 ::1:42039               :::*                    LISTEN      -                   \n",
      "tcp6       0      0 ::1:33363               :::*                    LISTEN      -                   \n",
      "udp        0      0 0.0.0.0:56953           0.0.0.0:*                           -                   \n",
      " \n",
      "\n",
      "----- END OF SSH OUTPUT -----\n",
      "\n",
      "Final model response with knowledge of the tool call result:\n",
      "\n",
      "Based on the output of the command `netstat -tunlp`, here are the network services running in the system along with their protocols and ports:\n",
      "\n",
      "1. **SSH Service**:\n",
      "   - Protocol: TCP\n",
      "   - Port: 22\n",
      "\n",
      "2. **Local Process Listening on Random Ports (PID not shown due to lack of root privileges)**:\n",
      "   - Multiple entries for 33363, 42039 both on IPv4 and IPv6 addresses.\n",
      "   - These are local processes listening on different ports.\n",
      "\n",
      "3. **UDP Service**:\n",
      "   - Protocol: UDP\n",
      "   - Port: 56953\n",
      "\n",
      "It should be noted that the PID is not shown for most of these services because the current user does not have root privileges, which is required to identify all process information accurately. For a complete and accurate list, one would need to run this command with sufficient permissions.\n",
      "\n",
      "For a more detailed analysis or if you require specific processes to be identified by their names, further steps such as using 'ps' commands could be taken but they too might require root privileges.\n",
      "------------ FINAL ANALYSIS ------------\n",
      "--------START OF INPUT--------\n",
      "--------- START OF ROUND 0 ---------------\n",
      "kali@192.168.40.132$ netstat -tunlp\n",
      "(Not all processes could be identified, non-owned process info\n",
      " will not be shown, you would have to be root to see it all.)\n",
      "Active Internet connections (only servers)\n",
      "Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \n",
      "tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -                   \n",
      "tcp        0      0 127.0.0.1:33363         0.0.0.0:*               LISTEN      -                   \n",
      "tcp        0      0 127.0.0.1:42039         0.0.0.0:*               LISTEN      -                   \n",
      "tcp6       0      0 ::1:42039               :::*                    LISTEN      -                   \n",
      "tcp6       0      0 ::1:33363               :::*                    LISTEN      -                   \n",
      "udp        0      0 0.0.0.0:56953           0.0.0.0:*                           -                   \n",
      "\n",
      "\n",
      "Based on the output of the command `netstat -tunlp`, here are the network services running in the system along with their protocols and ports:\n",
      "\n",
      "1. **SSH Service**:\n",
      "   - Protocol: TCP\n",
      "   - Port: 22\n",
      "\n",
      "2. **Local Process Listening on Random Ports (PID not shown due to lack of root privileges)**:\n",
      "   - Multiple entries for 33363, 42039 both on IPv4 and IPv6 addresses.\n",
      "   - These are local processes listening on different ports.\n",
      "\n",
      "3. **UDP Service**:\n",
      "   - Protocol: UDP\n",
      "   - Port: 56953\n",
      "\n",
      "It should be noted that the PID is not shown for most of these services because the current user does not have root privileges, which is required to identify all process information accurately. For a complete and accurate list, one would need to run this command with sufficient permissions.\n",
      "\n",
      "For a more detailed analysis or if you require specific processes to be identified by their names, further steps such as using 'ps' commands could be taken but they too might require root privileges.\n",
      "\n",
      "--------- END OF ROUND 0 ---------------\n",
      "\n",
      "--------END OF INPUT--------\n",
      "List all network services running in the system, including protocol and port\n",
      "\n",
      "Here are the network services running on your system:\n",
      "\n",
      "1. **SSH Service**:\n",
      "   - Protocol: TCP\n",
      "   - Port: 22\n",
      "\n",
      "2. Multiple Local Process Listening Services (with random ports):\n",
      "   - Protocols: TCP for IPv4 and IPv6\n",
      "   - Ports: 33363, 42039\n",
      "\n",
      "3. **UDP Service**:\n",
      "   - Protocol: UDP\n",
      "   - Port: 56953\n",
      "\n",
      "Note that the PID is not shown for most services because you lack root privileges, which are required to identify all processes accurately. To obtain a complete list with PIDs and process names, consider running `sudo netstat -tunlp`. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:39:13.169188Z",
     "start_time": "2025-04-05T19:39:08.938111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = \"Can you find a flag.txt in the system?\"\n",
    "run(task)"
   ],
   "id": "49c76b0a08861d00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model response requesting tool call:\n",
      "\n",
      "ChatCompletion(id='chatcmpl-uh9q4swl4ap8g541wddpzu', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='699293288', function=Function(arguments='{\"command\":\"find / -name flag.txt 2>/dev/null\"}', name='execute_ssh_command'), type='function')]))], created=1743881948, model='qwen2.5-7b-instruct-1m', object='chat.completion', service_tier=None, system_fingerprint='qwen2.5-7b-instruct-1m', usage=CompletionUsage(completion_tokens=30, prompt_tokens=534, total_tokens=564, completion_tokens_details=None, prompt_tokens_details=None), stats={})\n",
      "DEBUG ----- START OF SSH OUTPUT -----\n",
      "\n",
      " kali@192.168.40.132$ find / -name flag.txt 2>/dev/null\n",
      "/home/kali/secret/flag.txt\n",
      " \n",
      "\n",
      "----- END OF SSH OUTPUT -----\n",
      "\n",
      "Final model response with knowledge of the tool call result:\n",
      "\n",
      "I found the flag.txt file located at /home/kali/secret/flag.txt.\n",
      "------------ FINAL ANALYSIS ------------\n",
      "--------START OF INPUT--------\n",
      "--------- START OF ROUND 0 ---------------\n",
      "kali@192.168.40.132$ find / -name flag.txt 2>/dev/null\n",
      "/home/kali/secret/flag.txt\n",
      "\n",
      "\n",
      "I found the flag.txt file located at /home/kali/secret/flag.txt.\n",
      "\n",
      "--------- END OF ROUND 0 ---------------\n",
      "\n",
      "--------END OF INPUT--------\n",
      "The flag.txt file is located at /home/kali/secret/flag.txt.\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
